{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from torchvision import transforms\n",
    "import Resnet_18\n",
    "from polyvore_outfits import TripletImageLoader\n",
    "from tripletnet import Tripletnet\n",
    "from type_specific_network import TypeSpecificNet\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "\n",
    "gpu = 1\n",
    "\n",
    "global args\n",
    "args = SimpleNamespace(\n",
    "    batch_size = 256,\n",
    "    seed = 1,\n",
    "    cuda = torch.device(f\"cuda:{gpu}\"),\n",
    "    dim_embed = 64,\n",
    "    use_fc = True,\n",
    "    datadir=\"/home/fteotini/thesis\",\n",
    "    margin=0.3,\n",
    "    resume=\"/home/fteotini/thesis/type_aware/runs/nondis/model_best.pth.tar\",\n",
    "    polyvore_split=\"nondisjoint\",\n",
    "    rand_typespaces=False,\n",
    "    num_rand_embed=4,\n",
    "    learned=False,\n",
    "    prein=False,\n",
    "    l2_embed=False,\n",
    "    learned_metric=False\n",
    ")\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(args.datadir, \"polyvore_outfits\", \"polyvore_item_metadata.json\")\n",
    "with open(fn, \"r\") as fn_file:\n",
    "    meta_data = json.load(fn_file)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(112),\n",
    "    transforms.CenterCrop(112),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = TripletImageLoader(\n",
    "    args,\n",
    "    \"test\",\n",
    "    meta_data,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet_18.resnet18(pretrained=True, embedding_size=args.dim_embed)\n",
    "csn_model = TypeSpecificNet(args, model, len(dataset.typespaces))\n",
    "\n",
    "criterion = torch.nn.MarginRankingLoss(margin=args.margin)\n",
    "tnet = Tripletnet(args, csn_model, 6000, criterion).cuda(args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(args.resume)\n",
    "args.start_epoch = checkpoint[\"epoch\"]\n",
    "best_acc = checkpoint[\"best_prec1\"]\n",
    "tnet.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = args.batch_size,shuffle= False,num_workers=20,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnet.eval()\n",
    "embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, images in enumerate(dataloader):\n",
    "        images = images.cuda(args.cuda)\n",
    "        embeddings.append(tnet.embeddingnet(images))\n",
    "\n",
    "    embeddings = torch.cat(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"sip_data_nondisjoint.pkl\",'rb') as f:\n",
    "    sip_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for o in sip_data:\n",
    "    questions = o['src']\n",
    "    pos = o['ground_truth']\n",
    "    negs = o['negs']\n",
    "    for i in range(len(questions)):\n",
    "        seed = questions[:i + 1]\n",
    "        answers = [pos[i], *negs[i]]\n",
    "        scores = torch.zeros(len(answers), dtype=torch.float)\n",
    "        for idx, answer in enumerate(answers):\n",
    "            answer_type = dataset.im2type[answer]\n",
    "            score = 0.0\n",
    "            for s in seed:\n",
    "                s_type = dataset.im2type[s]\n",
    "                condition = dataset.get_typespace(s_type, answer_type)\n",
    "                embed_ans = embeddings[dataset.im2index[answer]][condition].unsqueeze(0)\n",
    "                embed_s = embeddings[dataset.im2index[s]][condition].unsqueeze(0)\n",
    "                \n",
    "                score += F.pairwise_distance(embed_ans, embed_s, 2)\n",
    "\n",
    "            scores[idx] = score.squeeze()\n",
    "        \n",
    "        results.append(torch.argmin(scores) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4196)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(list(map(lambda i: i.view(1),results))).sum() /len(results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb61270c69d91d50b5595a74afe2d760b8951df331f0569e5bbc2b8b14eb2a00"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('type_aware': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
